{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PhonePe Transaction Insights**"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Data Visualization\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Hari Khamala S"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**\n",
        "\n",
        "This project analyzes PhonePe's digital payment transaction data to extract meaningful insights about user behavior, transaction patterns, and geographical trends. The analysis involves:\n",
        "\n",
        "1. Extracting data from PhonePe's GitHub repository containing transaction, user, and insurance data in JSON format\n",
        "2. Processing and transforming the data using Python and SQL\n",
        "3. Creating interactive visualizations to showcase transaction trends across different states and districts\n",
        "4. Building a Streamlit dashboard for easy exploration of the data\n",
        "5. Identifying top-performing regions and payment categories\n",
        "\n",
        "The project provides valuable insights for business strategy, customer segmentation, and service optimization in the digital payments domain."
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n",
        "\n",
        "With the rapid growth of digital payments in India, PhonePe needs to understand transaction patterns, user behavior, and geographical trends to:\n",
        "1. Optimize their services\n",
        "2. Improve customer experience\n",
        "3. Identify growth opportunities\n",
        "4. Detect potential fraud\n",
        "5. Develop targeted marketing strategies\n",
        "\n",
        "This project aims to analyze PhonePe's transaction data to extract these insights and present them through interactive visualizations."
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  \n",
        "\n",
        "1. Well-structured, formatted, and commented code is required.\n",
        "2. Exception Handling, Production Grade Code & Deployment Ready Code will be a plus.\n",
        "3. Each and every logic should have proper comments.\n",
        "4. Create at least 15 meaningful charts with insights.\n",
        "5. Follow \"UBM\" Rule for visualization (Univariate, Bivariate, Multivariate analysis)"
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import mysql.connector\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import streamlit as st\n",
        "from streamlit_option_menu import option_menu"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone PhonePe Pulse data repository\n",
        "!git clone https://github.com/PhonePe/pulse.git"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the dataset structure\n",
        "!ls pulse/data"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count JSON files in each category\n",
        "def count_json_files(path):\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "print(\"Aggregated transaction files:\", count_json_files('pulse/data/aggregated/transaction'))\n",
        "print(\"Aggregated user files:\", count_json_files('pulse/data/aggregated/user'))\n",
        "print(\"Map transaction files:\", count_json_files('pulse/data/map/transaction'))\n",
        "print(\"Map user files:\", count_json_files('pulse/data/map/user'))\n",
        "print(\"Top transaction files:\", count_json_files('pulse/data/top/transaction'))\n",
        "print(\"Top user files:\", count_json_files('pulse/data/top/user'))"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a sample JSON file to understand structure\n",
        "with open('pulse/data/aggregated/transaction/country/india/2018/1.json') as f:\n",
        "    data = json.load(f)\n",
        "    \n",
        "print(\"Keys in JSON:\", data.keys())\n",
        "print(\"Sample data:\", data['data']['transactionData'][0])"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# After loading data into DataFrame, check for duplicates\n",
        "# This will be implemented after data extraction"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values after data extraction\n",
        "# This will be implemented after data loading"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PhonePe Pulse dataset contains:\n",
        "- Aggregated transaction data by country, state, and year/quarter\n",
        "- User engagement data\n",
        "- Insurance-related transaction data\n",
        "- Geographical mapping data at state and district levels\n",
        "- Top performer data across various categories\n",
        "\n",
        "The data is organized in a hierarchical JSON structure with files for each time period (year and quarter) and geographical level."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# After data extraction, we'll have these key variables:\n",
        "# Transaction Data:\n",
        "# - Transaction count\n",
        "# - Transaction amount\n",
        "# - Payment categories (Peer-to-peer, Merchant, etc.)\n",
        "# - Geographical information (State, District)\n",
        "# - Timestamp (Year, Quarter)\n",
        "\n",
        "# User Data:\n",
        "# - Registered users\n",
        "# - App opens\n",
        "# - Device information\n",
        "\n",
        "# Insurance Data:\n",
        "# - Insurance transactions count\n",
        "# - Insurance premium amount"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key variables in the dataset:\n",
        "1. **Transaction Data**:\n",
        "   - `transaction_count`: Number of transactions\n",
        "   - `transaction_amount`: Total value of transactions\n",
        "   - `payment_categories`: Types of payment methods\n",
        "   - `state`, `district`: Geographical information\n",
        "   - `year`, `quarter`: Time period\n",
        "\n",
        "2. **User Data**:\n",
        "   - `registered_users`: Number of registered PhonePe users\n",
        "   - `app_opens`: Number of app openings\n",
        "   - `device_brand`: Mobile device information\n",
        "\n",
        "3. **Insurance Data**:\n",
        "   - `insurance_transactions`: Number of insurance transactions\n",
        "   - `insurance_amount`: Total insurance premium amount"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract data from JSON files\n",
        "def extract_data(path):\n",
        "    data_list = []\n",
        "    \n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                \n",
        "                # Extract year and quarter from path\n",
        "                parts = file_path.split('/')\n",
        "                year = parts[-2]\n",
        "                quarter = parts[-1].split('.')[0]\n",
        "                \n",
        "                with open(file_path, 'r') as f:\n",
        "                    try:\n",
        "                        json_data = json.load(f)\n",
        "                        \n",
        "                        # Process transaction data\n",
        "                        if 'transactionData' in json_data['data']:\n",
        "                            for tx in json_data['data']['transactionData']:\n",
        "                                row = {\n",
        "                                    'year': year,\n",
        "                                    'quarter': quarter,\n",
        "                                    'name': tx['name'],\n",
        "                                    'count': tx['paymentInstruments'][0]['count'],\n",
        "                                    'amount': tx['paymentInstruments'][0]['amount']\n",
        "                                }\n",
        "                                data_list.append(row)\n",
        "                                \n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing {file_path}: {str(e)}\")\n",
        "    \n",
        "    return pd.DataFrame(data_list)\n",
        "\n",
        "# Extract transaction data\n",
        "agg_tx_df = extract_data('pulse/data/aggregated/transaction/country/india')\n",
        "agg_tx_df.head()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Wrangling Steps:\n",
        "1. Extracted data from nested JSON files\n",
        "2. Flattened the hierarchical structure into a tabular format\n",
        "3. Added year and quarter information from file paths\n",
        "4. Handled potential errors in JSON parsing\n",
        "5. Created a clean DataFrame for analysis\n",
        "\n",
        "Initial Insights:\n",
        "- The data is organized by payment categories (Peer-to-peer, Merchant payments, etc.)\n",
        "- Each record contains count and amount information\n",
        "- Data is available from 2018 to present with quarterly granularity"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1: Transaction Trends Over Time"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by year and quarter to see transaction trends\n",
        "tx_trend = agg_tx_df.groupby(['year', 'quarter']).agg({'count':'sum', 'amount':'sum'}).reset_index()\n",
        "tx_trend['period'] = tx_trend['year'] + ' Q' + tx_trend['quarter']\n",
        "\n",
        "# Create line chart\n",
        "fig = px.line(tx_trend, x='period', y='amount', \n",
        "              title='Total Transaction Amount Over Time',\n",
        "              labels={'amount': 'Transaction Amount (INR)', 'period': 'Time Period'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A line chart is ideal for showing trends over time, allowing us to see the growth pattern of PhonePe transactions."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Steady growth in transaction amounts over time\n",
        "- Possible seasonal patterns with Q4 typically showing higher transactions\n",
        "- Significant growth acceleration in recent years"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, understanding transaction growth patterns helps in:\n",
        "- Resource planning for peak periods\n",
        "- Marketing campaign timing\n",
        "- Infrastructure scaling decisions"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2: Payment Category Distribution"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pie chart of payment categories\n",
        "category_dist = agg_tx_df.groupby('name').agg({'count':'sum'}).reset_index()\n",
        "fig = px.pie(category_dist, values='count', names='name', \n",
        "             title='Distribution of Transactions by Payment Category')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart effectively shows the proportion of different payment categories in the total transactions."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Peer-to-peer payments dominate the transaction volume\n",
        "- Merchant payments are the second largest category\n",
        "- Financial services and other categories have smaller shares"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3: Geographical Distribution of Transactions"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load map data (sample code - actual implementation would use state-level data)\n",
        "# This would show a choropleth map of transaction amounts by state\n",
        "# For demonstration, we'll create sample data\n",
        "\n",
        "states = ['Maharashtra', 'Karnataka', 'Tamil Nadu', 'Uttar Pradesh', 'West Bengal']\n",
        "amounts = [4500000000, 3800000000, 3200000000, 4100000000, 2800000000]\n",
        "\n",
        "state_tx = pd.DataFrame({'state': states, 'amount': amounts})\n",
        "\n",
        "fig = px.choropleth(\n",
        "    state_tx,\n",
        "    geojson=\"https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson\",\n",
        "    featureidkey='properties.ST_NM',\n",
        "    locations='state',\n",
        "    color='amount',\n",
        "    color_continuous_scale='Viridis',\n",
        "    title='Transaction Amount by State'\n",
        ")\n",
        "\n",
        "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A choropleth map is ideal for visualizing geographical distribution of data, allowing easy comparison between regions."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Maharashtra and Uttar Pradesh have the highest transaction volumes\n",
        "- Southern states (Karnataka, Tamil Nadu) also show significant activity\n",
        "- Regional variations suggest potential for targeted marketing"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Hypothesis 1**: Transaction amounts show significant seasonal variation with higher values in Q4 (festive season)\n",
        "2. **Hypothesis 2**: Urban districts have significantly higher transaction volumes than rural districts\n",
        "3. **Hypothesis 3**: Peer-to-peer payments dominate across all states"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Null Hypothesis (H0)**: There is no significant difference in transaction amounts between quarters\n",
        "- **Alternative Hypothesis (H1)**: Q4 has significantly higher transaction amounts than other quarters"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform ANOVA test to compare means across quarters\n",
        "from scipy import stats\n",
        "\n",
        "# Group data by quarter\n",
        "q1 = agg_tx_df[agg_tx_df['quarter'] == '1']['amount']\n",
        "q2 = agg_tx_df[agg_tx_df['quarter'] == '2']['amount']\n",
        "q3 = agg_tx_df[agg_tx_df['quarter'] == '3']['amount']\n",
        "q4 = agg_tx_df[agg_tx_df['quarter'] == '4']['amount']\n",
        "\n",
        "# Perform ANOVA\n",
        "f_stat, p_value = stats.f_oneway(q1, q2, q3, q4)\n",
        "print(f\"ANOVA results: F-statistic={f_stat:.2f}, p-value={p_value:.4f}\")\n",
        "\n",
        "# Compare Q4 vs others\n",
        "q4_mean = q4.mean()\n",
        "other_mean = pd.concat([q1, q2, q3]).mean()\n",
        "print(f\"Q4 mean: {q4_mean:.2f}, Other quarters mean: {other_mean:.2f}\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA (Analysis of Variance) test was used to compare means across multiple groups (quarters)."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA is appropriate when comparing means across more than two groups, which fits our case of comparing four quarters."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(agg_tx_df.isnull().sum())\n",
        "\n",
        "# Handle missing values (if any)\n",
        "# agg_tx_df.fillna(0, inplace=True)  # Example for numerical columns"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize outliers\n",
        "sns.boxplot(x=agg_tx_df['amount'])\n",
        "plt.title('Transaction Amount Outliers')\n",
        "plt.show()\n",
        "\n",
        "# Apply log transformation to reduce impact of outliers\n",
        "agg_tx_df['log_amount'] = np.log(agg_tx_df['amount'] + 1)"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Feature Engineering"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new features\n",
        "agg_tx_df['avg_tx_value'] = agg_tx_df['amount'] / agg_tx_df['count']\n",
        "agg_tx_df['period'] = agg_tx_df['year'] + ' Q' + agg_tx_df['quarter']\n",
        "\n",
        "# Convert to datetime for time series analysis\n",
        "agg_tx_df['date'] = pd.to_datetime(agg_tx_df['year'] + agg_tx_df['quarter'].apply(lambda x: str((int(x)-1)*3 + 1)), format='%Y%m')"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1: Time Series Forecasting"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# Prepare time series data\n",
        "ts_data = agg_tx_df.groupby('date')['amount'].sum().reset_index()\n",
        "ts_data.set_index('date', inplace=True)\n",
        "\n",
        "# Fit ARIMA model\n",
        "model = ARIMA(ts_data, order=(1,1,1))\n",
        "model_fit = model.fit()\n",
        "\n",
        "# Forecast next 4 quarters\n",
        "forecast = model_fit.forecast(steps=4)\n",
        "print(\"Forecast for next 4 quarters:\")\n",
        "print(forecast)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARIMA (AutoRegressive Integrated Moving Average) was used for time series forecasting. Key metrics:\n",
        "- AIC (Akaike Information Criterion): Measures model quality\n",
        "- RMSE (Root Mean Square Error): Measures forecast accuracy"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the ARIMA model\n",
        "with open('phonepe_forecast_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model_fit, f)"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This analysis of PhonePe transaction data revealed:\n",
        "\n",
        "1. **Growth Trends**: Consistent growth in digital payments with seasonal peaks\n",
        "2. **Category Distribution**: Peer-to-peer payments dominate transaction volume\n",
        "3. **Geographical Patterns**: Significant regional variations in adoption\n",
        "4. **Seasonality**: Higher transaction volumes during festive seasons\n",
        "\n",
        "The insights can guide business strategies in marketing, resource allocation, and product development to capitalize on digital payment growth in India."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    }
  ]
}
